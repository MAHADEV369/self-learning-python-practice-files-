import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def binary_cross_entropy(y_true, y_pred):
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))

y_true = np.array([1, 0, 1])  # True labels
y_pred = np.array([0.9, 0.2, 0.8])  # Predicted probabilities
loss = binary_cross_entropy(y_true, y_pred)
print("Binary Cross-Entropy Loss", loss)
